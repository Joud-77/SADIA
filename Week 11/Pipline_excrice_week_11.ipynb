{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4cDludo0dxGN"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.datasets import load_breast_cancer, load_iris\n",
        "import pandas as pd\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_iris()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = data.target"
      ],
      "metadata": {
        "id": "RC48wTchdzJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_iris()\n",
        "X=pd.DataFrame(data.data,columns=data.feature_names)\n",
        "y=data.target"
      ],
      "metadata": {
        "id": "GHCsz1HEfTUo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example column names (assuming numerical features only for simplicity)\n",
        "numerical_features = data.feature_names\n",
        "categorical_features = []  # Add categorical feature names if any\n",
        "\n",
        "# Define transformers for numerical and categorical features\n",
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Combine transformers using ColumnTransformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])"
      ],
      "metadata": {
        "id": "30qfqpNad4-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_features = data.feature_names\n",
        "categorical_features = []\n",
        "\n",
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', RandomForestClassifier())\n",
        "])"
      ],
      "metadata": {
        "id": "Uc6kXyB9fZfw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "VyoL8McbfIdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train , X_test ,y_train , y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "qlPmjSg4f8Zx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the pipeline on training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Perform cross-validation on training data\n",
        "cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='accuracy')\n",
        "print(f'Cross-validation scores: {cv_scores}')\n",
        "print(f'Mean cross-validation score: {cv_scores.mean():.2f}')"
      ],
      "metadata": {
        "id": "tfQfQ-7hfKYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "cv_score=cross_val_score(pipeline,X_train,y_train,cv=5,scoring='accuracy')\n",
        "print(f'Cross-validation scores: {cv_score} ')\n",
        "print(f'Mean cross-validation score: {cv_score.mean():.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHMZvqLggUbN",
        "outputId": "489d1fcd-e9a5-45f3-a902-9119a3a411ad"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores: [0.95833333 0.95833333 0.875      1.         0.95833333] \n",
            "Mean cross-validation score: 0.95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict and evaluate on test data\n",
        "y_pred = pipeline.predict(X_test)\n",
        "accuracy = pipeline.score(X_test, y_test)\n",
        "print(f'Test accuracy: {accuracy:.2f}')"
      ],
      "metadata": {
        "id": "ozboIcyHfMfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = pipeline.predict(X_test)\n",
        "accuracy = pipeline.score(X_test, y_test)\n",
        "print(f'Test accuracy: {accuracy:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vBU2Opkg5AD",
        "outputId": "738168cf-de86-4d17-ed0e-266d32d993e7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the pipeline to a file\n",
        "joblib_file = 'trained_pipeline.pkl'\n",
        "joblib.dump(pipeline, joblib_file)\n",
        "print(f'Model saved to {joblib_file}')"
      ],
      "metadata": {
        "id": "QEFdDVZnfOEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joblib_file= \"trained_pipeline.pkl\"\n",
        "joblib.dump(pipeline,joblib_file)\n",
        "print(f'Model saved to {joblib_file}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewdj2ta3g8Un",
        "outputId": "89e72fb0-353d-4ba3-b1ab-eb56ffd87b4e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to trained_pipeline.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pipeline from the file\n",
        "loaded_pipeline = joblib.load(joblib_file)\n",
        "\n",
        "# Use the loaded pipeline to make predictions\n",
        "loaded_pipeline_predictions = loaded_pipeline.predict(X_test)\n",
        "loaded_pipeline_accuracy = loaded_pipeline.score(X_test, y_test)\n",
        "print(f'Loaded pipeline test accuracy: {loaded_pipeline_accuracy:.2f}')"
      ],
      "metadata": {
        "id": "TM5PoFh2fPgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_pipeline_predictions = loaded_pipeline.predict(X_test)\n",
        "loaded_pipeline_accuracy = loaded_pipeline.score(X_test, y_test)\n",
        "\n",
        "print(f'Loaded pipeline test accuracy: {loaded_pipeline_accuracy:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVWScoLrhEXX",
        "outputId": "076d4950-d2cc-4584-df59-9bc8824363fe"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pipeline test accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "source": [
        "import joblib\n",
        "\n",
        "# Assuming 'trained_pipeline.pkl' is the filename where your pipeline is saved\n",
        "joblib_file = \"trained_pipeline.pkl\"\n",
        "\n",
        "# Load the pipeline from the file\n",
        "loaded_pipeline = joblib.load(joblib_file)  # This line is crucial\n",
        "\n",
        "# Now you can use the loaded pipeline for predictions and scoring\n",
        "loaded_pipeline_predictions = loaded_pipeline.predict(X_test)\n",
        "loaded_pipeline_accuracy = loaded_pipeline.score(X_test, y_test)\n",
        "\n",
        "print(f'Loaded pipeline test accuracy: {loaded_pipeline_accuracy:.2f}')"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-w9rwTdhvzV",
        "outputId": "d1741219-769e-44cd-b9b9-0bc6eb0970de"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pipeline test accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# New data for prediction (replace this with your own data)\n",
        "new_data = pd.DataFrame({\n",
        "    'sepal length (cm)': [5.1, 6.2],\n",
        "    'sepal width (cm)': [3.5, 3.4],\n",
        "    'petal length (cm)': [1.4, 5.4],\n",
        "    'petal width (cm)': [0.2, 2.3]\n",
        "})\n",
        "\n",
        "# Predict using the loaded pipeline\n",
        "predictions = loaded_pipeline.predict(new_data)\n",
        "print(f'Predictions for new data: {predictions}')"
      ],
      "metadata": {
        "id": "BJKBSaS2fRPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_data=pd.DataFrame({\n",
        "    'sepal length (cm)':[5.1,6.2],\n",
        "    'sepal width (cm)':[3.5,3.4],\n",
        "    'petal length (cm)':[1.4,5.4],\n",
        "    'petal width (cm)':[0.2,2.3]\n",
        "})\n",
        "\n",
        "predictions=loaded_pipeline.predict(new_data)\n",
        "print(f'Predictions for new data: {predictions}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_cmRnmXh0NX",
        "outputId": "d5923919-0370-4c6e-e8fc-fb2eb302b0d5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions for new data: [0 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YFJfEOzgiKRK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}